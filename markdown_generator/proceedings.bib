@inproceedings{kuhn2014movie,
    title = {MOVIE: Large Scale Automated Analysis of MOVing ImagEs},
    author = {Kuhn, Virginia and Marini, Luigi and Simeone, Michael and Craig, Alan and Diesendruck, Liana and Puthanveetil Satheesan, Sandeep and Bock, David},
    booktitle = {Proceedings of the Conference on Extreme Science and Engineering Discovery Environment: Engaging Communities},
    year = {2014},
    organization = {ACM}
}

@inproceedings{kuhn2015vat,
    title = {The Vat: enhanced video analysis},
    author = {Kuhn, Virginia and Craig, Alan and Simeone, Michael and Puthanveetil Satheesan, Sandeep and Marini, Luigi},
    booktitle = {Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure},
    pages = {11},
    year = {2015},
    organization = {ACM}
}

@inproceedings{padhy2016architecture,
    author = {Padhy, Smruti and Alameda, Jay and Kooper, Rob and Liu, Rui and Satheesan, Sandeep Puthanveetil and Zharnitsky, Inna and Jansen, Gregory and Dietze, Michael C. and Kumar, Praveen and Lee, Jong and Marciano, Richard and Marini, Luigi and Minsker, Barbara and Navarro, Chris and Slavenas, Marcus and Sullivan, William and McHenry, Kenton},
    title = {An Architecture for Automatic Deployment of Brown Dog Services at Scale into Diverse Computing Infrastructures},
    year = {2016},
    isbn = {9781450347556},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2949550.2949647},
    doi = {10.1145/2949550.2949647},
    abstract = {Brown Dog is an extensible data cyberinfrastructure, that provides a set of extensible and distributed data conversion and metadata extraction services to enable access and search within unstructured, un-curated and inaccessible research data across different domains of sciences and social science, which ultimately aids in supporting reproducibility of results. We envision that Brown Dog, as a data cyberinfrastructure, is an essential service in a comprehensive cyberinfrastructure which includes data services, high performance computing services and more that would enable scholarly research in a variety of disciplines that today is not yet possible. Brown Dog focuses on four initial use cases, specifically, addressing the conversion and extraction needs in the research areas of ecology, civil and environmental engineering, library and information science, and use by the general public. In this paper, we describe an architecture that supports contribution of data transformation tools from users, and automatic deployment of the tools as Brown Dog services in diverse infrastructures such as cloud or high performance computing (HPC) based on user demands and load on the system. We also present results validating the performance of the initial implementation of Brown Dog.},
    booktitle = {Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale},
    articleno = {33},
    numpages = {8},
    keywords = {Data conversion, HPC, Metadata extraction, Elasticity, Library and Information Science, Data cyberinfrastructure, Autocuration, Cloud, Civil and Environmental Engineering, Ecology, Digital preservation},
    location = {Miami, USA},
    series = {XSEDE16}
}

@inproceedings{mchenry2016brown,
    title = {Brown Dog - A Science Driven Data Transformation Service},
    author = {Kenton McHenry and Jong Lee and Barbara Minsker and Jay Alameda and Shannon Bradley and Luigi Marini and Rob Kooper and CHRISTOPHER NAVARRO and Smruti Padhy and Marcus Slavenas and Sandeep Satheesan and Yan Zhao and Bing Zhang and Inna Zharnitsky and Eugene Roeder},
    booktitle = {Gateways 2016},
    year = {2016},
    url = {https://figshare.com/articles/journal_contribution/Brown_Dog_A_Science_Driven_Data_Transformation_Service/4490735},
}

@inproceedings{rodriguez2017extracting,
    title = {Extracting, Assimilating, and Sharing the Results of Image Analysis on the FSA/OWI Photography Collection},
    author = {Rodriguez, Paul and Puthanveetil Satheesan, Sandeep and Will, Jeffrey and Wuerffel, Elizabeth and Craig, Alan},
    booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact},
    pages = {42},
    year = {2017},
    organization = {ACM}
}

@inproceedings{langmead2017extracting,
    title = {Extracting Meaningful Data from Decomposing Bodies},
    author = {Langmead, Alison and Rodriguez, Paul and Puthanveetil Satheesan, Sandeep and Craig, Alan},
    booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact},
    pages = {41},
    year = {2017},
    organization = {ACM}
}

@inproceedings{satheesan2018brown,
    author = {Satheesan, Sandeep Puthanveetil and Alameda, Jay and Bradley, Shannon and Dietze, Michael and Galewsky, Benjamin and Jansen, Gregory and Kooper, Rob and Kumar, Praveen and Lee, Jong and Marciano, Richard and Marini, Luigi and Minsker, Barbara S. and Navarro, Christopher M. and Schmidt, Arthur and Slavenas, Marcus and Sullivan, William C. and Zhang, Bing and Zhao, Yan and Zharnitsky, Inna and McHenry, Kenton},
    title = {Brown Dog: Making the Digital World a Better Place, a Few Files at a Time},
    year = {2018},
    isbn = {9781450364461},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3219104.3219132},
    doi = {10.1145/3219104.3219132},
    abstract = {Brown Dog is a data transformation service for auto-curation of long-tail data. In this digital age, we have more data available for analysis than ever and this trend will only increase. According to most estimates, 70--80% of this data is unstructured, and together with unsupported data formats and inaccessible software tools, in essence, this data is not either easily accessible or usable to its owners in a meaningful way. Brown Dog aims at making this data more accessible and usable by auto-curation and indexing, leveraging existing and novel data transformation tools. In this paper, we discuss the recent major component improvements to Brown Dog including transformation tools called extractors and converters; desktop, web and terminal-based clients which perform data transformations; libraries written in multiple programming languages which integrate with existing software and extend their data curation capabilities; an online tool store for users to contribute, manage and share data transformation tools and receive credit for developing them; cyberinfrastructure for deploying the system on diverse computing platforms leveraging scalability via Docker swarm; workflow management service for creatively integrating existing transformations to generate custom, reproducible workflows which meet research needs, and its data management capabilities. This paper also discusses data transformation tools developed to support some scientific and allied use cases, thereby benefiting researchers in diverse domains. Finally, we briefly discuss our future directions with regard to production deployments as well as how users can access Brown Dog to manage their un-curated unstructured data.},
    booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing},
    articleno = {38},
    numpages = {8},
    keywords = {data wrangling, data conversion, orchestration, data transformation, big data, unstructured data, metadata extraction, API gateway, data curation, provenance, auto-curation, data cyberinfrastructure},
    location = {Pittsburgh, PA, USA},
    series = {PEARC '18}
}

@inproceedings{satheesan2019extensible,
    author = {Satheesan, Sandeep Puthanveetil and Bhattarai, Rabin and Bradley, Shannon and Coppess, Jonathan and Gatzke, Lisa and Gupta, Rishabh and Jeong, Hanseok and Lee, Jong S. and Naraharisetty, Gowtham and Ondrejcek, Michal and Schnitkey, Gary D. and Zhao, Yan and Navarro, Christopher M.},
    title = {Extensible Framework for Analysis of Farm Practices and Programs},
    year = {2019},
    isbn = {9781450372275},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3332186.3337063},
    doi = {10.1145/3332186.3337063},
    abstract = {We present an open source extensible web framework for the analysis of different farm practices and programs and easy dissemination of their results to the users. Currently, this framework is being applied to two use cases --- a web-based decision support system for cover crop management and a web-based farm program analysis tool to assist farmers, academics, and policymakers to understand programs and policies surrounding the Farm Bill. Through the first use case, we address the problem of bridging the gap between the scientific research that happens in labs and experimental plots and the day to day practices and decisions taken by the farmers in the fields. Specifically, this use case focuses on the practice of cover crops, their management, and the impact on reducing nutrient runoff into water bodies. Through the second use case, we address the problem of predicting the expected payment amounts and measured risk or probability of payment for different government insurance programs authorized by the 2018 Farm Bill, namely the Agriculture Risk Coverage (ARC) and Price Loss Coverage (PLC). This helps the farmers compare these programs based on forecasted crop yields and prices. In this paper, we describe the overall architecture of the framework and its major components, the use cases that are currently benefiting from using this framework and share screenshots of the web applications developed using this framework for those use cases. We also share our plans for future work and conclusions about applying this framework to the two use cases.},
    booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (Learning)},
    articleno = {11},
    numpages = {8},
    keywords = {web framework, Agricultural Risk Coverage (ARC) program, Decision Support System for Agrotechnology Transfer (DSSAT), farm practices analysis, Price Loss Coverage (PLC) program, Gulf of Mexico hypoxia zone, cover crop management, farm programs analysis, web-based decision support system, nitrate nitrogen, crop commodity programs analysis, workflow management system, farm bill, nutrient runoff, nitrogen leaching, crop modeling},
    location = {Chicago, IL, USA},
    series = {PEARC '19}
}

@inproceedings{marini2019clowder,
    author = {Marini, Luigi and Gutierrez-Polo, Indira and Kooper, Rob and Satheesan, Sandeep Puthanveetil and Burnette, Maxwell and Lee, Jong and Nicholson, Todd and Zhao, Yan and McHenry, Kenton},
    title = {Clowder: Open Source Data Management for Long Tail Data},
    year = {2018},
    isbn = {9781450364461},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3219104.3219159},
    doi = {10.1145/3219104.3219159},
    abstract = {Clowder is an open source data management system to support data curation of long tail data and metadata across multiple research domains and diverse data types. Institutions and labs can install and customize their own instance of the framework on local hardware or on remote cloud computing resources to provide a shared service to distributed communities of researchers. Data can be ingested directly from instruments or manually uploaded by users and then shared with remote collaborators using a web front end. We discuss some of the challenges encountered in designing and developing a system that can be easily adapted to different scientific areas including digital preservation, geoscience, material science, medicine, social science, cultural heritage and the arts. Some of these challenges include support for large amounts of data, horizontal scaling of domain specific preprocessing algorithms, ability to provide new data visualizations in the web browser, a comprehensive Web service API for automatic data ingestion and curation, a suite of social annotation and metadata management features to support data annotation by communities of users and algorithms, and a web based front-end to interact with code running on heterogeneous clusters, including HPC resources.},
    booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing},
    articleno = {40},
    numpages = {8},
    keywords = {data curation, data management, linked data, metadata management, scientific gateways},
    location = {Pittsburgh, PA, USA},
    series = {PEARC '18}
}

@inproceedings{satheesan2017brown,
    author = {{Puthanveetil Satheesan}, S. and {Alameda}, J. and {Bradley}, S. and {Dietze}, M. and {Jansen}, G. and {Kooper}, R. and {Kumar}, P. and {Lee}, J. and {Marciano}, R. and {Marini}, L. and {Minsker}, B.~S. and {Navarro}, C. and {Roeder}, E. and {Schmidt}, A. and {Slavenas}, M. and {Sullivan}, W. and {Zhang}, B. and {Zhao}, Y. and {Zharnitsky}, I. and {McHenry}, K.},
    title = {Brown Dog: A Data Transformation Ecosystem for Research - Advancing from Beta to 1.0},
    keywords = {1916 Data and information discovery, INFORMATICS, 1946 Metadata, INFORMATICS, 1950 Metadata: Quality, INFORMATICS},
    booktitle = {AGU Fall Meeting Abstracts},
    year = 2017,
    volume = {2017},
    month = dec,
    eid = {IN21B-0038},
    pages = {IN21B-0038},
    adsurl = {https://ui.adsabs.harvard.edu/abs/2017AGUFMIN21B0038P},
    adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{satheesan2013feature,
    title = {A feature information based approach for enhancing score-level fusion in multi-sample biometric systems},
    author = {Satheesan, Sandeep Puthanveetil and Tulyakov, Sergey and Govindaraju, Venu},
    booktitle = {2013 Fourth National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG)},
    pages = {1--4},
    year = {2013},
    organization = {IEEE}
}

@inproceedings{satheesan2019historical,
    title = {A Historical Big Data Analysis to Understand the Social Construction of Juvenile Delinquency in the United States},
    author = {Satheesan, Sandeep Puthanveetil and Craig, Alan B and Zhang, Yu},
    booktitle = {2019 15th International Conference on eScience (eScience)},
    pages = {636--637},
    year = {2019},
    organization = {IEEE}
}

@misc{puthanveetil2013groupscope,
    title = {Groupscope: A Microscope for Large Dynamic Groups Research},
    author = {Puthanveetil Satheesan, Sandeep and Poole, Marshall Scott and Kooper, Rob and McHenry, Kenton},
    booktitle = {IEEE 9th International Conference on eScience (eScience)},
    url = {https://escience2013.csp.escience.cn/dct/page/65605},
    year = {2013},
    howpublished = {Poster presented at IEEE 9th International Conference on eScience (eScience)},
}

@misc{poole2015groupscope,
    title = {GroupScope: A Framework and Tools for Large Scale Study of Social Processes},
    author = {Poole, Marshall Scott and Lambert, Natalie and Puthanveetil Satheesan, Sandeep and Das, Amit and Yahja, Alex and Hasegawa-Johnson, Mark},
    booktitle = {International Conference On Computational Science, ICCS 2015},
    url = {http://www.iccss2015.eu/},
    year = {2015},
    howpublished = {Poster presented at International Conference On Computational Science, ICCS 2015},
}